<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kiyosumaeda.github.io/">Kiyosu Maeda</a><sup>1</sup>,</span>
            <span class="author-block">
              William P. McCarthy<sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.chingyitsai.com">Ching-Yi Tsai</a><sup>1</sup>,
            </span>
            <span class="author-block">
              Jeffrey Mu<sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://haoliangwang.github.io/">Haoliang Wang</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://rdhawkins.com/">Robert D. Hawkins</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://psychology.stanford.edu/people/judith-ellen-fan">Judith E. Fan</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://parastooabtahi.com/">Parastoo Abtahi</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Princeton University</span>
            <span class="author-block"><sup>2</sup>University of California, San Diego</span>
            <span class="author-block"><sup>3</sup>Brown University</span>
            <span class="author-block"><sup>4</sup>MIT</span>
            <span class="author-block"><sup>5</sup>Stanford University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://hci.princeton.edu/wp-content/uploads/sites/459/2026/02/Maeda_Gesturing_Toward_Abstraction_CHI2026.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2602.08914"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Unimodal Study Link. -->
              <span class="link-block">
                <a href="https://github.com/cogtoolslab/compositional-abstractions"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Unimodal Study</span>
                </a>
              </span>
              <!-- Multimodal Study Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Multimodal Study</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1gFImf2TGn2mO35KELEc4BPoyrvj1Lajh"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Viewing App Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1lO_w2P03JdNqt_H6fVlwW7TxiDp5T5qG"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-hand-peace"></i>
                  </span>
                  <span>Viewing App</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/studyshifts.png" alt="Teaser figure showing shifts in multimodal signals" style="width: 100%; height: auto;">
      <p class=" has-text-centered" style="font-style: italic; margin-top: 0.5rem;">
        Figure 1. Shifts in multimodal signals (speech and gesture) in instructions from the first repetition (R1) to the final repetition (R2) for the same tower. A) Multimodal signals for position and orientation of block-level instructions shift from redundant in R1 to complementary in R4. B) For tower-level instructions, no position or orientation information is provided when establishing a convention in R1, but redundancy is introduced to emphasize position and orientation changes in R4. C) The virtual target tower that the Instructor saw on the 2×2 grid.
      </p>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner’s hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <div class="columns is-centered has-text-centered is-light">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Viewing the Dataset</h2>
      <div class="content has-text-justified">
        <p>
        The viewing application allows replay of study data, showing 4D hand movements of Instructors synchronized with the audio transcript of their verbal instructions, as shown in the example video above. The viewing app also shows the target tower and the reference 2×2 grid. To view the multimodal study data:
        </p>
        <ol>
        <li>Download the viewing app linked above.</li>
        <li>Unzip and open the Mac application.</li>
        <li>Set the metadata fields on the top left for the participant, trial, and step you want to view:
          <ul>
          <li>Participant ID: "P<i>", i ∈ {1, …, 21} and i ≠ 18</li>
          <li>Trial ID: "&lt;t&gt;", t ∈ {1, …, 12}</li>
          <li>Step ID: "&lt;s&gt;", s ∈ {1, 2, 3, 4}</li>
          </ul>
        </li>
        <li>Load and Play.</li>
        <li>Right-click and drag to change the viewing angle.</li>
        </ol>
      </div>
      </div>
    </div>

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Example Data Video</h2>
      <div class="publication-video">
        <iframe src="./static/videos/Multimodal Conventions Example.mp4"
            frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
      <p style="font-size: 0.875rem; font-style: italic; margin-top: 0.5rem;">
        *The original audio file has been removed for anonymity and replaced with a re-recording of the participants' audio transcript for demonstration purposes.
      </p>
      </div>
    </div>

    
    <!--/ Paper video. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{Maeda2026GesturingTowardAbstraction,
  author = {Maeda, Kiyosu and McCarthy, William P. and Tsai, Ching-Yi and Mu, Jeffrey and Wang, Haoliang and Hawkins, Robert D. and Fan, Judith E. and Abtahi, Parastoo},
  title = {Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks},
  booktitle = {Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems},
  series = {CHI '26},
  year = {2026},
  location = {Barcelona, Spain},
  numpages = {15},
  url = {https://doi.org/10.1145/3772318.3790618},
  doi = {10.1145/3772318.3790618},
  publisher = {ACM},
  address = {New York, NY, USA}}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website is built from the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> here.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
